Check the RSS feeds for collective.contentgenerator
=====================================================

Web resources dependency test by Ed Crewe, ILRT 
(University of Bristol) January 2009

When the content generator creates a site it does so
by crawling out real content from the web. So unless
a crawl of content has already been done for a 
site instance, there is a dependency on the system 
having a web connection and that the sites it relies 
on, the BBC and Flickr are up. Finally the feeds and 
categories it uses must be available.

First create a contentgenerator class to obtain its resources data

    >>> from collective.contentgenerator.ContentGenerator import ContentSetup
    >>> cs=ContentSetup()

Now import the methods to check the urls and parse the content returned 

    >>> from urllib import urlopen
    >>> from xml.dom.minidom import parseString

Generate one sample url to see if the web is available 

    >>> sampleurl = cs.bbc % cs.feeds[0]
    >>> data = urlopen(sampleurl).read()
    >>> len(data) > 100
    True

Go through each feed generating the full url and getting the items it contains
then confirm that there are items in each one

    >>> for category in cs.feeds:
    ...     feed = cs.bbc % category
    ...     data = urlopen(feed).read()
    ...     dom = parseString(data)
    ...     items = dom.getElementsByTagName('item')
    ...     if not items:
    ...         items = dom.getElementsByTagName('entry')
    ...     len(items)>0
    True
    True
    True
    True
    True
    True
    True
    True
    True
    True
    True
    True

Check the image feeds too 

    >>> for category in cs.ftags:
    ...     feed = cs.flickr % category
    ...     data = urlopen(feed).read()
    ...     dom = parseString(data)
    ...     items = dom.getElementsByTagName('item')
    ...     if not items:
    ...         items = dom.getElementsByTagName('entry')
    ...     len(items)>0
    True
    True
    True
    True
    True
    True
    True
    True
    

