0.7.0 (2007-03-21):
- Added DebuggingParser module. It provides a subclass of ZestyParser that prints a comprehensive trace of all parsing. It's very useful for tracking down the sources of parsing anomalies.
- Added Lookahead and Negative token types. They both are initialized with another token object. Lookahead scans for that token and returns the result but then returns the parser's cursor to its original position; Negative does the same but only matches (and returns True) if the token failed to match. (AbstractToken overloads the ~ operator to return a Negative of self.)
- Added Only flag for TokenSequence elements. If one of these is present in a TokenSequence, only that token's result will be returned instead of the whole list.
- ZestyParser.scan and methods with related semantics no longer accept iterables as arguments; you should use CompositeToken for the same effect (which, for the most part, just means replacing your commas with |s).
- Added a `pad` method to Skip instances. Passed a TokenSequence, it returns a copy of the sequence with itself interjected between every two elements. Useful for skipping whitespace in large constructions.
- Added fairly complete unit tests (currently in examples/unittests.py).
- Renamed AbstractToken's `as` property to `to`, since `as` is becoming a reserved word in Python 2.6. Passing the initializer an `as` keyword argument still works, for backwards compatibility, but it is deprecated and will be removed in a future version.
- Added Const factory function which, called with any value, returns a function suitable for use as an AbstractToken callback which always returns that value.
- Added TokenWrapper, an AbstractToken subclass initialized with another valid token. When called, it transparently calls that token and returns the result. This is intended to be used as a function decorator, so that if you need to write a custom token that can be expressed simply as a function, you can do so but still get all the benefits of AbstractToken.
- ZestyParser.iter is now a generator method, eliminating the need for the ParserIterator class.
- AbstractToken now has a faster and more reliable way of checking how many arguments a callback takes.
- AbstractToken subclasses no longer have to pass the result through AbstractToken.preprocessResult in their __call__ methods; AbstractToken handles that automatically.
- Changed CallbackFor into a factory function instead of a class.
- Optimized TokenSeries and AbstractToken a bit.
- Cleaned up some tokens' initializers.

0.6.0 (2007-01-12):
- Added `elements' example. Parses chemical formulae. I wrote this to see how much code it would take in comparison to the equivalent part of a pyparsing example I found, in which it takes 6 lines. It takes 1 line in ZestyParser.
- Added an example more complex than any of the earlier ones: `n3'. It is a fairly complete parser for the RDF Notation3 format. Included are n3.py, which returns an abstract parse tree, and n3rdflib.py, which takes that parse tree and adds all the information to an RDFLib graph.
- Added a new file to the library, AHT.py, which provides "Ad Hoc Types". Useful for building abstract parse trees.
- Added `context' property to ZestyParser instances. This can be used by your programs to store state information during parsing, if necessary.
- Added `as' property to AbstractToken instances (and a corresponding keyword parameter before `name' to its subclasses' initializers). This is either None or a one-argument callable to be used for post-post-processing after any callback. Mainly intended to be an AHT.
- Rewrote the code that lets AbstractToken callbacks take between one and three arguments. It's more reliable now.
- Added Default token type, which does not consume any characters in the input stream, and always returns a given value.
- Redefined EmptyToken in terms of Default('').
- Removed `addTokens' method of ZestyParser (and `tokens' property). They are obsolete at this point.
- Added includeDelimiter property (and initializer argument) to TokenSeries. Default false; if true, the delimiter will be included in the returned list, instead of omitted.
- TokenSeries is now a bit faster, since it doesn't use TokenSequence internally.
- Added Omit wrapper to be used with TokenSequence elements. Like Skip, which indicates that a token should be considered optional and not included in the returned list, Omit indicates that the token's return value should not be included in the result, but should still be required.
- EOF is now an instance of a private AbstractToken subclass, instead of simply a function, so you can now perform any of the usual operations (^, +, etc.) on it.
- New epydoc-based documentation. Much better than the old docs.

0.5.1 (2007-01-08):
- Added `until' support to ZestyParser.iter and TokenSeries. Stops at this token instead of stopping only when no more tokens can be matched.

0.5.0 (2007-01-08):
- Separated token classes from Parser.py into a separate Tokens.py file. Easier to navigate.
- Added keyword argument caseInsensitive to RawToken's initializer. Does just what it looks like. (Previously, RawToken was always case-sensitive.)
- Added TokenSeries token type, which matches another token a number of times, in a given range. You can also specify tokens to be used as a prefix, suffix, delimiter, etc. Awesome powaa! bdecode.py now requires only 5 lines of actual code to set up its tokens!
- Added Defer token type. Takes a callable which must itself return a token, and scans for that. This is so you can use a lambda to refer to a not-yet-defined token. This is now the preferred way of defining potentially-recursive tokens.
- Added Skip token type, mainly intended to be used with `TokenSequence`. It encapsulates another token, and if TokenSequence encounters one, it has the effect of calling `skip()` instead of `scan()` on a `ZestyParser` instance, and the return value is not included in the sequence's returned list.
- Added EmptyToken object, which always successfully matches nothing. It is used internally by TokenSeries, but it may have some other minor applications.
- Added `group' property of `Token' objects (passed as an optional keyword argument to its initializer); if this is present, it will return that group of the regex match object, instead of the whole match object.
- Removed `ReturnRaw', which is obsoleted by the above.
- Added inline modification (+=, |=) support to TokenSequence and CompositeToken.
- List-based tokens (CompositeToken, TokenSequence, etc.) now properly handle internal recursion when asked for a string representation.
- Added `plist' example, which parses Apple's pre-XML property list format.
- Optimized the examples a bit, as usual.

0.4.2 (2006-12-31):
- Added more overloading: (token ^ message) results in a new token which will raise ParseError with `message' if it fails to match.
- Removed the `scanMultiple' and `take' methods.
- Added a `TakeToken` token type, which is initialized with a length, and matches exactly that number of characters.
- As usual, optimized/updated examples to take advantage of new features. sexp.py is down to 34 lines, from 77 in the original release!
- Removed the `quotey' example. Turns out there's a much simpler way to do that with Python's re module. That's what I get for having worked with PHP for so long, eh?
- Speaking of PHP and examples -- added an example of parsing PHP's serialize format. 29 zesty lines!

0.4.1 (2006-12-28):
- Tiny bugfix. Zoop! (That's what I get when I make a last-minute change that I assume will work and don't test it, eh?)

0.4.0 (2006-12-27): Big update! Big, compatibility-breaking update!
- Added CallbackFor function intended to be used as a decorator. Call it as @CallbackFor(someToken) above a function, and the function will be replaced with that token, itself becoming that token's callback.
- To save space when you don't need certain informations, callbacks can now take between one and three arguments. If three, it will be passed, as usual, the parser, the data, and the original cursor. If two, it will be passed the parser and the data. If one, it will be simply passed the data.
- Added some overloading magic. Now you can construct CompositeTokens by chaining other tokens together with the | operator, and TokenSequences by chaining other tokens together with the + operator.
- More overloading magic: (token >> callable) results in a copy of `token' with its callback set to `callable'. Useful for concisely specifying a callback for the outcome of a + or | sequence, since you don't get direct access to the initializer in such cases.
- Removed `name' as the first argument to tokens' initializers. It was not very useful, in retrospect. If you do need something like that for debugging, you can pass a name in the `name' keyword argument.
- Several optimizations. Now zestier than ever!
- Added RawToken class, which matches only an exact string. Faster than using regex matching if you're only looking for a constant.
- ZestyParser.scan() now returns the matching data or callback result directly, rather than as the second item in a tuple (the first being the token object). Instead, you can access the last-matched token via ZestyParser's `last' property.
- ZestyParser.addTokens() can also take keyword arguments; each value will be taken as a token to be added, and its key will be set as its name.
- Added ZestyParser.skip() method, which takes one token as an argument, matches it, and returns a boolean indicating whether it matched or not. Can be faster than using scan() if you're just doing something like skipping whitespace.
- Added an example for parsing BitTorrent's bencode format.
- Rewrote calcy.py example yet again. Zestiness (and readability) increased!
- Improved sexp.py example similarly.

0.3.0 (2006-12-21)
- The previous distributions didn't actually include the examples. Oho!
- Added a ParseError exception, for programs to raise when they encounter something they weren't expecting.
- Mainly useful for the ParseError exception, but abstract enough to be used in other ways, added a coord() method to ZestyParser, returning the current row and column of the cursor.

0.2.0 (2006-12-18)
- Added some worthwhile internal abstractions.
- Rewrote calcy.py example to use new features and be a bit more concise.
- Changed NotMatched to an exception. Duh.
- Added built-in ReturnDirect token callback. I'm not going to bother explaining it here, because I'm only writing this as of 0.4.0, by which point ReturnDirect is obsolete.
- Added addToken method on ZestyParser class, allowing code to refer to tokens by name instead of by reference; useful for mutually-recursive tokens.

0.1.0 (2006-12-17)
- Initial release.
