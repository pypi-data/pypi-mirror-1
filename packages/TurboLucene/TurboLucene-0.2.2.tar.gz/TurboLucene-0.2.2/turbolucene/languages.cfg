#==============================================================================
# turbolucene/languages.cfg
#
# This is part of the TurboLucene project (http://dev.krys.ca/turbolucene/).
#
# Copyright (c) 2007 Krys Wilken <krys AT krys DOT ca>
#
# This software is licensed under the MIT license.  See the LICENSE file for
# licensing information.
#
#==============================================================================


# Czech
[cs]
analyzer_class = CzechAnalyzer
# Stopwords taken from http://www.ranks.nl/stopwords/czech.html
stopwords_file = stopwords_cs.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = iso-8859-1


# Danish
[da]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Danish
# Stopwords taken from http://snowball.tartarus.org/algorithms/danish/stop.txt
stopwords_file = stopwords_da.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# German
[de]
analyzer_class = SnowballAnalyzer
# See http://snowball.tartarus.org/algorithms/german2/stemmer.html for details
# on why German2 was chosen as default.
analyzer_class_args = German2
# Stopwords taken from http://snowball.tartarus.org/algorithms/german/stop.txt
stopwords_file = stopwords_de.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Greek
[el]
analyzer_class = GreekAnalyzer
# No Greek stopwords could be easily found.  The GreekAnalyzer has some built-
# in, but PyLucene does not export it for viewing/manipulation.
# If you specify any keywords here, it will override, not extend the built-in
# ones.


# English
[en]
analyzer_class = SnowballAnalyzer
analyzer_class_args = English
# Stopwords taken from http://snowball.tartarus.org/algorithms/english/stop.txt
stopwords_file = stopwords_en.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = iso-8859-1


# Spanish
[es]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Spanish
# Stopwords taken from http://snowball.tartarus.org/algorithms/spanish/stop.txt
stopwords_file = stopwords_es.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Finnish
[fi]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Finnish
# Stopwords taken from http://snowball.tartarus.org/algorithms/finnish/stop.txt
stopwords_file = stopwords_fi.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# French
[fr]
analyzer_class = SnowballAnalyzer
analyzer_class_args = French
# Stopwords taken from http://snowball.tartarus.org/algorithms/french/stop.txt
stopwords_file = stopwords_fr.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Italian
[it]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Italian
# Stopwords taken from http://snowball.tartarus.org/algorithms/italian/stop.txt
stopwords_file = stopwords_it.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Japanese
[ja]
analyzer_class = CJKAnalyzer
# No Japanese stopwords could be easily found.  The CJKAnalyzer has some built-
# in English stopwords and some double-byte interpunctions, but PyLucene does
# not export it for viewing/manipulation.  If you specify any keywords here, it
# will override, not extend the built-in ones.
#
# The only stopwords I could find for Japanese is in the source code of
# mnoGoSearch (tm) (http://www.mnogosearch.org/).  The stopwords are in
# etc/stopwords/ja.sl of the source tarball.  It, however cannot be included
# here because mnoGoSearch (tm) is licensed under the GPL and TurboLucene is
# not.  If you want to download mnoGoSearch (tm) yourself and copy the
# etc/stopwords/ja.sl file to stopwords/stopwords_ja.txt, then you can
# uncomment the lines below.  You will also have to change the header of the
# file, replacing each # with | as TurboLucene cannot process # comments.
#
# NOTE: If you do this, you cannot redistribute your copy of TurboLucene under
# the MIT license.  It will have to be GPLed.  Otherwise, I would have already
# included it. :-)

# # Stopwords taken from http://www.mnogosearch.org/
# stopwords_file = stopwords_ja.txt
# stopwords_file_encoding = eucjp


# Korean
[ko]
analyzer_class = CJKAnalyzer
# No Korean stopwords could be easily found.  The CJKAnalyzer has some built-
# in English stopwords and some double-byte interpunctions, but PyLucene does
# not export it for viewing/manipulation.  If you specify any keywords here, it
# will override, not extend the built-in ones.


# Dutch
[nl]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Dutch
# Stopwords taken from http://snowball.tartarus.org/algorithms/dutch/stop.txt
stopwords_file = stopwords_nl.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = iso-8859-1


# Norwegian
[no]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Norwegian
# Stopwords taken from
# http://snowball.tartarus.org/algorithms/norwegian/stop.txt
stopwords_file = stopwords_no.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Portuguese
[pt]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Portuguese
# Stopwords taken from
# http://snowball.tartarus.org/algorithms/portuguese/stop.txt
stopwords_file = stopwords_pt.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Brazilian
[pt-br]
analyzer_class = BrazilianAnalyzer
# No Brazilian stopwords could be easily found.  The BrazilianAnalyzer has some
# built-in, but PyLucene does not export it for viewing/manipulation.  If you
# specify any keywords here, it will override, not extend the built-in ones.


# Russian
[ru]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Russian
# Stopwords taken from http://snowball.tartarus.org/algorithms/russian/stop.txt
stopwords_file = stopwords_ru.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = koi8_r


# Swedish
[sv]
analyzer_class = SnowballAnalyzer
analyzer_class_args = Swedish
# Stopwords taken from http://snowball.tartarus.org/algorithms/swedish/stop.txt
stopwords_file = stopwords_sv.txt
# Encoding determined by Firefox :-)
stopwords_file_encoding = windows-1252


# Chinese
[zh]
analyzer_class = CJKAnalyzer
# No Chinese stopwords could be easily found.  The CJKAnalyzer has some built-
# in English stopwords and some double-byte interpunctions, but PyLucene does
# not export it for viewing/manipulation.  If you specify any keywords here, it
# will override, not extend the built-in ones.
#
# The only stopwords I could find for Chinese is in the source code of
# mnoGoSearch (tm) (http://www.mnogosearch.org/).  The stopwords are in
# etc/stopwords/zh.sl of the source tarball.  It, however cannot be included
# here because mnoGoSearch (tm) is licensed under the GPL and TurboLucene is
# not.  If you want to download mnoGoSearch (tm) yourself and copy the
# etc/stopwords/zh.sl file to stopwords/stopwords_zh.txt, then you can
# uncomment the lines below.  You will also have to change the header of the
# file, replacing each # with | as TurboLucene cannot process # comments.
#
# NOTE: If you do this, you cannot redistribute your copy of TurboLucene under
# the MIT license.  It will have to be GPLed.  Otherwise, I would have already
# included it. :-)

# # Stopwords taken from http://www.mnogosearch.org/
# stopwords_file = stopwords_zh.txt
# stopwords_file_encoding = gb2312
